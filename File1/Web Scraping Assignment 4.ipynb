{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de642baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f2d55",
   "metadata": {},
   "source": [
    "### 1. Scrape  the  details  of  most  viewed  videos  on  YouTube  from  Wikipedia.  Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:  A) Rank   B) Name   C) Artist   D) Upload date   E) Views   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6e149fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2bd1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7ac19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "upload_date=[]\n",
    "views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "619b226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping name from the given page\n",
    "name_tag=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "try:\n",
    "    for i in name_tag:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Exception Raised\",e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba50391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Baby Shark Dance\"[7]', '\"Despacito\"[10]', '\"Johny Johny Yes Papa\"[18]', '\"Bath Song\"[19]', '\"Shape of You\"[20]', '\"See You Again\"[23]', '\"Wheels on the Bus\"[28]', '\"Phonics Song with Two Words\"[29]', '\"Uptown Funk\"[30]', '\"Gangnam Style\"[31]', '\"Learning Colors – Colorful Eggs on a Farm\"[36]', '\"Dame Tu Cosita\"[37]', '\"Masha and the Bear – Recipe for Disaster\"[38]', '\"Axel F\"[39]', '\"Sugar\"[40]', '\"Baa Baa Black Sheep\"[41]', '\"Counting Stars\"[42]', '\"Lakdi Ki Kathi\"[43]', '\"Roar\"[44]', '\"Waka Waka (This Time for Africa)\"[45]', '\"Sorry\"[46]', '\"Shree Hanuman Chalisa\"[47]', '\"Humpty the train on a fruits ride\"[48]', '\"Thinking Out Loud\"[49]', '\"Perfect\"[50]', '\"Dark Horse\"[51]', '\"Let Her Go\"[52]', '\"Faded\"[53]', '\"Girls Like You\"[54]', '\"Lean On\"[55]']\n"
     ]
    }
   ],
   "source": [
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c5e5a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping artist name from the given page\n",
    "artist_tag=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "try:\n",
    "    for i in artist_tag:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Exception Raised\",e) \n",
    "    \n",
    "# scraping upload date from the given page\n",
    "date_tag=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "try:\n",
    "    for i in date_tag:\n",
    "        upload_date.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Exception Raised\",e) \n",
    "    \n",
    "# scraping views from the given page\n",
    "views_tag=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "try:\n",
    "    for i in views_tag:\n",
    "        views.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Exception Raised\",e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c342906b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(artist),len(upload_date),len(views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07fbd219",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2685392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Rank':rank,'Name':name,'Artist':artist,'Upload Date':upload_date,'Views':views})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efb960e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                                             Name  \\\n",
      "0      1                            \"Baby Shark Dance\"[7]   \n",
      "1      2                                  \"Despacito\"[10]   \n",
      "2      3                       \"Johny Johny Yes Papa\"[18]   \n",
      "3      4                                  \"Bath Song\"[19]   \n",
      "4      5                               \"Shape of You\"[20]   \n",
      "5      6                              \"See You Again\"[23]   \n",
      "6      7                          \"Wheels on the Bus\"[28]   \n",
      "7      8                \"Phonics Song with Two Words\"[29]   \n",
      "8      9                                \"Uptown Funk\"[30]   \n",
      "9     10                              \"Gangnam Style\"[31]   \n",
      "10    11  \"Learning Colors – Colorful Eggs on a Farm\"[36]   \n",
      "11    12                             \"Dame Tu Cosita\"[37]   \n",
      "12    13   \"Masha and the Bear – Recipe for Disaster\"[38]   \n",
      "13    14                                     \"Axel F\"[39]   \n",
      "14    15                                      \"Sugar\"[40]   \n",
      "15    16                        \"Baa Baa Black Sheep\"[41]   \n",
      "16    17                             \"Counting Stars\"[42]   \n",
      "17    18                             \"Lakdi Ki Kathi\"[43]   \n",
      "18    19                                       \"Roar\"[44]   \n",
      "19    20           \"Waka Waka (This Time for Africa)\"[45]   \n",
      "20    21                                      \"Sorry\"[46]   \n",
      "21    22                      \"Shree Hanuman Chalisa\"[47]   \n",
      "22    23          \"Humpty the train on a fruits ride\"[48]   \n",
      "23    24                          \"Thinking Out Loud\"[49]   \n",
      "24    25                                    \"Perfect\"[50]   \n",
      "25    26                                 \"Dark Horse\"[51]   \n",
      "26    27                                 \"Let Her Go\"[52]   \n",
      "27    28                                      \"Faded\"[53]   \n",
      "28    29                             \"Girls Like You\"[54]   \n",
      "29    30                                    \"Lean On\"[55]   \n",
      "\n",
      "                                               Artist        Upload Date  \\\n",
      "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
      "1                                          Luis Fonsi   January 12, 2017   \n",
      "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
      "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
      "4                                          Ed Sheeran   January 30, 2017   \n",
      "5                                         Wiz Khalifa      April 6, 2015   \n",
      "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
      "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
      "8                                         Mark Ronson  November 19, 2014   \n",
      "9                                                 Psy      July 15, 2012   \n",
      "10                                        Miroshka TV  February 27, 2018   \n",
      "11                                      Ultra Records      April 5, 2018   \n",
      "12                                         Get Movies   January 31, 2012   \n",
      "13                                         Crazy Frog      June 16, 2009   \n",
      "14                                           Maroon 5   January 14, 2015   \n",
      "15                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
      "16                                        OneRepublic       May 31, 2013   \n",
      "17                                       Jingle Toons      June 14, 2018   \n",
      "18                                         Katy Perry  September 5, 2013   \n",
      "19                                            Shakira       June 4, 2010   \n",
      "20                                      Justin Bieber   October 22, 2015   \n",
      "21                              T-Series Bhakti Sagar       May 10, 2011   \n",
      "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
      "23                                         Ed Sheeran    October 7, 2014   \n",
      "24                                         Ed Sheeran   November 9, 2017   \n",
      "25                                         Katy Perry  February 20, 2014   \n",
      "26                                          Passenger      July 25, 2012   \n",
      "27                                        Alan Walker   December 3, 2015   \n",
      "28                                           Maroon 5       May 31, 2018   \n",
      "29                               Major Lazer Official     March 22, 2015   \n",
      "\n",
      "    Views  \n",
      "0   14.32  \n",
      "1    8.41  \n",
      "2    6.89  \n",
      "3    6.66  \n",
      "4    6.23  \n",
      "5    6.22  \n",
      "6    6.01  \n",
      "7    5.75  \n",
      "8    5.18  \n",
      "9    5.10  \n",
      "10   5.09  \n",
      "11   4.59  \n",
      "12   4.57  \n",
      "13   4.45  \n",
      "14   4.02  \n",
      "15   4.01  \n",
      "16   4.00  \n",
      "17   3.98  \n",
      "18   3.98  \n",
      "19   3.89  \n",
      "20   3.78  \n",
      "21   3.77  \n",
      "22   3.76  \n",
      "23   3.75  \n",
      "24   3.70  \n",
      "25   3.70  \n",
      "26   3.64  \n",
      "27   3.60  \n",
      "28   3.58  \n",
      "29   3.57  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1335cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f046e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1f5ee5b",
   "metadata": {},
   "source": [
    "### 2. Scrape the details team India’s international fixtures from bcci.tv.  Url = https://www.bcci.tv/.   You need to find following details:   \n",
    "A) Series   \n",
    "B) Place   \n",
    "C) Date   \n",
    "D) Time   \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c680945",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de20769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbc8f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on see all to see all the fixtures\n",
    "see=driver.find_element(By.XPATH,'/html/body/div[6]/div[1]/div/div/div[2]/div/div[2]/div/div[1]/div[1]/a')\n",
    "see.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e82dba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "335c0ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping series data from the given page\n",
    "ser=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "try:\n",
    "    for i in ser:\n",
    "        series.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Exception Raised:\",e)\n",
    "    \n",
    "# scraping place data from the given page\n",
    "pl=driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')\n",
    "try:\n",
    "    for i in pl:\n",
    "        place.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Exception Raised:\",e)\n",
    "    \n",
    "# scraping date data from the given page\n",
    "da=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "try:\n",
    "    for i in da:\n",
    "        date.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Exception Raised:\",e)\n",
    "    \n",
    "# scraping time data from the given page\n",
    "ti=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "try:\n",
    "    for i in ti:\n",
    "        time.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Exception Raised:\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fe438ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9 9 9\n"
     ]
    }
   ],
   "source": [
    "print(len(series),len(place),len(date),len(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f2a6844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Series  \\\n",
      "0  ICC MENS T20 WORLD CUP 2024   \n",
      "1  ICC MENS T20 WORLD CUP 2024   \n",
      "2  ICC MENS T20 WORLD CUP 2024   \n",
      "3  ICC MENS T20 WORLD CUP 2024   \n",
      "4  INDIA TOUR OF ZIMBABWE 2024   \n",
      "5  INDIA TOUR OF ZIMBABWE 2024   \n",
      "6  INDIA TOUR OF ZIMBABWE 2024   \n",
      "7  INDIA TOUR OF ZIMBABWE 2024   \n",
      "8  INDIA TOUR OF ZIMBABWE 2024   \n",
      "\n",
      "                                               Place           Date  \\\n",
      "0  Nassau County International Cricket Stadium, N...   5 JUNE, 2024   \n",
      "1  Nassau County International Cricket Stadium, N...   9 JUNE, 2024   \n",
      "2  Nassau County International Cricket Stadium, N...  12 JUNE, 2024   \n",
      "3  Central Broward Park & Broward County Stadium,...  15 JUNE, 2024   \n",
      "4                         Harare Sports Club, Harare   6 JULY, 2024   \n",
      "5                         Harare Sports Club, Harare   7 JULY, 2024   \n",
      "6                         Harare Sports Club, Harare  10 JULY, 2024   \n",
      "7                         Harare Sports Club, Harare  13 JULY, 2024   \n",
      "8                         Harare Sports Club, Harare  14 JULY, 2024   \n",
      "\n",
      "          Time  \n",
      "0  8:00 PM IST  \n",
      "1  8:00 PM IST  \n",
      "2  8:00 PM IST  \n",
      "3  8:00 PM IST  \n",
      "4  8:00 PM IST  \n",
      "5  8:00 PM IST  \n",
      "6  8:00 PM IST  \n",
      "7  8:00 PM IST  \n",
      "8  8:00 PM IST  \n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({'Series':series,'Place':place,'Date':date,'Time':time})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf287ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "041bd832",
   "metadata": {},
   "source": [
    "### 3. Scrape the details of State-wise GDP of India from statisticstime.com.   \n",
    "Url = http://statisticstimes.com/   \n",
    "You have to find following details: A) Rank   \n",
    "B) State   \n",
    "C) GSDP(23-24)- at current prices   \n",
    "D) GSDP(22-23)- at current prices   \n",
    "E) Share(21-22)   \n",
    "F) GDP($ billion)   \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e3a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5e9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\" http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "544eed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87efb47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on India under ecomony section\n",
    "Ind=driver.find_element(By.XPATH,'//div[@class=\"dropdown\"][2]/div/a[3]')\n",
    "try:\n",
    "    Ind.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(Ind.get_attribute('href'))\n",
    "    \n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15a22c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Indian State GDP\n",
    "state = driver.find_element(By.XPATH,'//ul[@style=\"list-style-type:none;margin-left:20px;\"]/li[1]/a')\n",
    "try:\n",
    "    state.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(state.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c841db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty lists\n",
    "Rank =[]\n",
    "State =[]\n",
    "GSDP_23_24=[]\n",
    "GSDP_22_23 =[]\n",
    "Share =[]\n",
    "GDP =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe6c56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank via Xpath\n",
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "    \n",
    "# Extracting state name via Xpath\n",
    "try:\n",
    "    state=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "    for i in state:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append('NA')\n",
    "    \n",
    "# Extracting GSDP 23 24 via Xpath\n",
    "try:\n",
    "    gsdp_23_24=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "    for i in gsdp_23_24:\n",
    "        GSDP_23_24.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_23_24.append('NA')\n",
    "    \n",
    "# Extracting GSDP 22 23 via Xpath\n",
    "try:\n",
    "    gsdp_22_23=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "    for i in gsdp_22_23:\n",
    "        GSDP_22_23.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_22_23.append('NA')\n",
    "    \n",
    "# Extracting share in billons via Xpath\n",
    "try:\n",
    "    share=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "    for i in share:\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append('NA')\n",
    "\n",
    "# Extracting GDP via Xpath\n",
    "try:\n",
    "    gdp=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[7]')\n",
    "    for i in gdp:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "327c9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for scrap data\n",
    "df=pd.DataFrame({'Rank':Rank,'State':State,'GSDP 23-24':GSDP_23_24,'GSDP 22-23':GSDP_22_23,\n",
    "                            'Share':Share,'GDP (in Billions)':GDP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d618f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP 23-24</th>\n",
       "      <th>GSDP 22-23</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP (in Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>13.17%</td>\n",
       "      <td>414.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,700,109</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>8.78%</td>\n",
       "      <td>276.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,500,733</td>\n",
       "      <td>2,269,995</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>264.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>2,547,861</td>\n",
       "      <td>2,258,040</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>263.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>2,230,609</td>\n",
       "      <td>8.17%</td>\n",
       "      <td>257.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,700,939</td>\n",
       "      <td>1,531,758</td>\n",
       "      <td>5.63%</td>\n",
       "      <td>177.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,524,030</td>\n",
       "      <td>1,365,849</td>\n",
       "      <td>5.06%</td>\n",
       "      <td>159.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,439,674</td>\n",
       "      <td>1,303,524</td>\n",
       "      <td>4.87%</td>\n",
       "      <td>153.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,463,960</td>\n",
       "      <td>1,308,034</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>150.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,363,327</td>\n",
       "      <td>1,246,471</td>\n",
       "      <td>4.63%</td>\n",
       "      <td>145.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>1,046,188</td>\n",
       "      <td>3.96%</td>\n",
       "      <td>124.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>1,107,746</td>\n",
       "      <td>1,014,688</td>\n",
       "      <td>3.73%</td>\n",
       "      <td>117.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>1,095,535</td>\n",
       "      <td>984,055</td>\n",
       "      <td>3.68%</td>\n",
       "      <td>116.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>832,790</td>\n",
       "      <td>753,177</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>88.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>-</td>\n",
       "      <td>751,396</td>\n",
       "      <td>2.76%</td>\n",
       "      <td>86.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>736,423</td>\n",
       "      <td>676,164</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>565,401</td>\n",
       "      <td>493,167</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>505,887</td>\n",
       "      <td>464,399</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>-</td>\n",
       "      <td>393,722</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>47.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>346,206</td>\n",
       "      <td>303,781</td>\n",
       "      <td>1.13%</td>\n",
       "      <td>35.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>246,465</td>\n",
       "      <td>224,226</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>25.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>207,430</td>\n",
       "      <td>191,728</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>22.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>-</td>\n",
       "      <td>93,672</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>11.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>-</td>\n",
       "      <td>72,636</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>54,285</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>6.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>-</td>\n",
       "      <td>49,643</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>47,381</td>\n",
       "      <td>42,697</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>-</td>\n",
       "      <td>42,756</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>39,630</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>35,643</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP 23-24 GSDP 22-23   Share  \\\n",
       "0     1                Maharashtra          -          -  13.17%   \n",
       "1     2                 Tamil Nadu  2,700,109  2,364,514   8.78%   \n",
       "2     3                  Karnataka  2,500,733  2,269,995   8.38%   \n",
       "3     4              Uttar Pradesh  2,547,861  2,258,040   8.37%   \n",
       "4     5                    Gujarat          -  2,230,609   8.17%   \n",
       "5     6                West Bengal  1,700,939  1,531,758   5.63%   \n",
       "6     7                  Rajasthan  1,524,030  1,365,849   5.06%   \n",
       "7     8             Andhra Pradesh  1,439,674  1,303,524   4.87%   \n",
       "8     9                  Telangana  1,463,960  1,308,034   4.76%   \n",
       "9    10             Madhya Pradesh  1,363,327  1,246,471   4.63%   \n",
       "10   11                     Kerala          -  1,046,188   3.96%   \n",
       "11   12                      Delhi  1,107,746  1,014,688   3.73%   \n",
       "12   13                    Haryana  1,095,535    984,055   3.68%   \n",
       "13   14                     Odisha    832,790    753,177   2.81%   \n",
       "14   15                      Bihar          -    751,396   2.76%   \n",
       "15   16                     Punjab    736,423    676,164   2.62%   \n",
       "16   17                      Assam    565,401    493,167   1.74%   \n",
       "17   18               Chhattisgarh    505,887    464,399   1.74%   \n",
       "18   19                  Jharkhand          -    393,722   1.52%   \n",
       "19   20                Uttarakhand    346,206    303,781   1.13%   \n",
       "20   21            Jammu & Kashmir    246,465    224,226   0.82%   \n",
       "21   22           Himachal Pradesh    207,430    191,728   0.73%   \n",
       "22   23                        Goa          -     93,672   0.36%   \n",
       "23   24                    Tripura          -     72,636   0.27%   \n",
       "24   25                 Chandigarh          -     54,285   0.20%   \n",
       "25   26                 Puducherry          -     49,643   0.19%   \n",
       "26   27                  Meghalaya     47,381     42,697   0.16%   \n",
       "27   28                     Sikkim          -     42,756   0.16%   \n",
       "28   29                    Manipur          -          -   0.16%   \n",
       "29   30          Arunachal Pradesh          -     39,630   0.15%   \n",
       "30   31                   Nagaland          -     35,643   0.13%   \n",
       "31   32                    Mizoram          -          -   0.12%   \n",
       "32   33  Andaman & Nicobar Islands          -          -   0.04%   \n",
       "\n",
       "   GDP (in Billions)  \n",
       "0            414.928  \n",
       "1            276.522  \n",
       "2            264.080  \n",
       "3            263.747  \n",
       "4            257.484  \n",
       "5            177.456  \n",
       "6            159.334  \n",
       "7            153.324  \n",
       "8            150.084  \n",
       "9            145.913  \n",
       "10           124.764  \n",
       "11           117.660  \n",
       "12           116.001  \n",
       "13            88.497  \n",
       "14            86.817  \n",
       "15            82.397  \n",
       "16            54.930  \n",
       "17            54.806  \n",
       "18            47.909  \n",
       "19            35.664  \n",
       "20            25.813  \n",
       "21            22.984  \n",
       "22            11.250  \n",
       "23             8.351  \n",
       "24             6.154  \n",
       "25             5.849  \n",
       "26             5.178  \n",
       "27             5.014  \n",
       "28             4.885  \n",
       "29             4.643  \n",
       "30             4.144  \n",
       "31             3.715  \n",
       "32             1.385  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2b2f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4e91b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0b35789",
   "metadata": {},
   "source": [
    "### 4. Scrape the details of trending repositories on Github.com.   \n",
    "Url = https://github.com/   \n",
    "You have to find the following details:   \n",
    "A) Repository title   \n",
    "B) Repository description   \n",
    "C) Contributors count   \n",
    "D) Language used  \n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca33bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4771014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening github page\n",
    "driver.get(' https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e0b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on open source\n",
    "os=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "os.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e5501c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on trending option\n",
    "trend=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "try:\n",
    "    trend.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trend.get_attribute('href'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "757648ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty list for Scraping Data\n",
    "Title=[]\n",
    "Description=[]\n",
    "Count =[]\n",
    "Language =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af6299c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping repositories URL\n",
    "URL= []\n",
    "link=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in link:\n",
    "    URL.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a14eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "321ce36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping required data\n",
    "for i in URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # scraping repository title\n",
    "    try:\n",
    "        title=driver.find_elements(By.XPATH,'//span[@class=\"author flex-self-stretch\"]')\n",
    "        for i in title:\n",
    "            Title.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Title.append('-')\n",
    "        \n",
    "    # scraping repository description\n",
    "    try:\n",
    "        desc=driver.find_elements(By.XPATH,'//p[@class=\"f4 mb-3 \"]')\n",
    "        for i in desc:\n",
    "            Description.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "        \n",
    "    # scraping contribution count\n",
    "    try:\n",
    "        cc=driver.find_elements(By.XPATH,'//span[@class=\"Counter ml-1\"]')\n",
    "        for i in cc:\n",
    "            Count.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Count.append('-')\n",
    "        \n",
    "    # scraping language used\n",
    "    L=[]\n",
    "    try:\n",
    "        lang=driver.find_elements(By.XPATH,'//span[@class=\"color-fg-default text-bold mr-1\"]')\n",
    "        if lang:\n",
    "            for j in lang:\n",
    "                L.append(j.text)\n",
    "        else:\n",
    "            L.append('NA')\n",
    "        Language.append(L)\n",
    "    except NoSuchElementException:\n",
    "        Language.append('-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5a822ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Language),len(Description),len(Count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e7620d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Title':Title,'Description':Description,'Contributors_count':Count,'Language_used':Language})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a37c20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plandex-ai</td>\n",
       "      <td>An AI coding engine for complex tasks</td>\n",
       "      <td>7</td>\n",
       "      <td>[Go, Shell, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HardhatChad</td>\n",
       "      <td>计算机自学指南</td>\n",
       "      <td>4</td>\n",
       "      <td>[Rust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PKUFlyingPig</td>\n",
       "      <td>AstroNvim is an aesthetic and feature-rich neo...</td>\n",
       "      <td>120</td>\n",
       "      <td>[HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HardhatChad</td>\n",
       "      <td>freeCodeCamp.org's open-source codebase and cu...</td>\n",
       "      <td>79</td>\n",
       "      <td>[Rust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AstroNvim</td>\n",
       "      <td>📚 Freely available programming books</td>\n",
       "      <td>4,981</td>\n",
       "      <td>[Lua]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>freeCodeCamp</td>\n",
       "      <td>A collective list of free APIs</td>\n",
       "      <td>2,863</td>\n",
       "      <td>[TypeScript, JavaScript, CSS, Dockerfile, MDX,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EbookFoundation</td>\n",
       "      <td>free</td>\n",
       "      <td>1,262</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>public-apis</td>\n",
       "      <td>Reaching LLaMA2 Performance with 0.1M Dollars</td>\n",
       "      <td>1</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aurora-develop</td>\n",
       "      <td>🚀🎉📚 SaaS Boilerplate built with Next.js + Tail...</td>\n",
       "      <td>13</td>\n",
       "      <td>[Go, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>myshell-ai</td>\n",
       "      <td>Windows in a Docker container.</td>\n",
       "      <td>4</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ixartz</td>\n",
       "      <td>Interactive roadmaps, guides and other educati...</td>\n",
       "      <td>1</td>\n",
       "      <td>[TypeScript, JavaScript, CSS, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dockur</td>\n",
       "      <td>SearXNG is a free internet metasearch engine w...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Shell, Dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kamranahmedse</td>\n",
       "      <td>Vim-fork focused on extensibility and usability</td>\n",
       "      <td>765</td>\n",
       "      <td>[TypeScript, Astro, JavaScript, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>searxng</td>\n",
       "      <td>🎓 Path to a free self-taught education in Comp...</td>\n",
       "      <td>220</td>\n",
       "      <td>[Python, Shell, HTML, Less, JavaScript, CSS, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cloudflare</td>\n",
       "      <td>[GPT beats diffusion🔥] [scaling laws in visual...</td>\n",
       "      <td>26</td>\n",
       "      <td>[TypeScript, JavaScript, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>availproject</td>\n",
       "      <td>Learn how to design large-scale systems. Prep ...</td>\n",
       "      <td>1,260</td>\n",
       "      <td>[Rust, Dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>neovim</td>\n",
       "      <td>A React Framework for building internal tools,...</td>\n",
       "      <td>36</td>\n",
       "      <td>[Vim Script, C, Lua, CMake, Python, Shell, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>availproject</td>\n",
       "      <td>A multi core friendly rigid body physics and c...</td>\n",
       "      <td>140</td>\n",
       "      <td>[Rust, HTML, JavaScript, CSS, TypeScript, Shel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ossu</td>\n",
       "      <td>⛓️ Langflow is a dynamic graph where each node...</td>\n",
       "      <td>2</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FoundationVision</td>\n",
       "      <td>-</td>\n",
       "      <td>22</td>\n",
       "      <td>[Python, Jupyter Notebook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pagefaultgames</td>\n",
       "      <td>-</td>\n",
       "      <td>118</td>\n",
       "      <td>[TypeScript, PowerShell, PLSQL, JavaScript, HT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>donnemartin</td>\n",
       "      <td>-</td>\n",
       "      <td>221</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>refinedev</td>\n",
       "      <td>-</td>\n",
       "      <td>43</td>\n",
       "      <td>[TypeScript, JavaScript, CSS, HTML, Handlebars...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jrouwe</td>\n",
       "      <td>-</td>\n",
       "      <td>85</td>\n",
       "      <td>[C++, C, CMake, HLSL, JavaScript, Batchfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>logspace-ai</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[JavaScript, Python, TypeScript, CSS, Shell, D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Title                                        Description  \\\n",
       "0         plandex-ai              An AI coding engine for complex tasks   \n",
       "1        HardhatChad                                            计算机自学指南   \n",
       "2       PKUFlyingPig  AstroNvim is an aesthetic and feature-rich neo...   \n",
       "3        HardhatChad  freeCodeCamp.org's open-source codebase and cu...   \n",
       "4          AstroNvim               📚 Freely available programming books   \n",
       "5       freeCodeCamp                     A collective list of free APIs   \n",
       "6    EbookFoundation                                               free   \n",
       "7        public-apis      Reaching LLaMA2 Performance with 0.1M Dollars   \n",
       "8     aurora-develop  🚀🎉📚 SaaS Boilerplate built with Next.js + Tail...   \n",
       "9         myshell-ai                     Windows in a Docker container.   \n",
       "10            ixartz  Interactive roadmaps, guides and other educati...   \n",
       "11            dockur  SearXNG is a free internet metasearch engine w...   \n",
       "12     kamranahmedse    Vim-fork focused on extensibility and usability   \n",
       "13           searxng  🎓 Path to a free self-taught education in Comp...   \n",
       "14        cloudflare  [GPT beats diffusion🔥] [scaling laws in visual...   \n",
       "15      availproject  Learn how to design large-scale systems. Prep ...   \n",
       "16            neovim  A React Framework for building internal tools,...   \n",
       "17      availproject  A multi core friendly rigid body physics and c...   \n",
       "18              ossu  ⛓️ Langflow is a dynamic graph where each node...   \n",
       "19  FoundationVision                                                  -   \n",
       "20    pagefaultgames                                                  -   \n",
       "21       donnemartin                                                  -   \n",
       "22         refinedev                                                  -   \n",
       "23            jrouwe                                                  -   \n",
       "24       logspace-ai                                                  -   \n",
       "\n",
       "   Contributors_count                                      Language_used  \n",
       "0                   7                                 [Go, Shell, Other]  \n",
       "1                   4                                             [Rust]  \n",
       "2                 120                                             [HTML]  \n",
       "3                  79                                             [Rust]  \n",
       "4               4,981                                              [Lua]  \n",
       "5               2,863  [TypeScript, JavaScript, CSS, Dockerfile, MDX,...  \n",
       "6               1,262                                               [NA]  \n",
       "7                   1                                    [Python, Shell]  \n",
       "8                  13                                        [Go, Other]  \n",
       "9                   4                                           [Python]  \n",
       "10                  1               [TypeScript, JavaScript, CSS, Shell]  \n",
       "11                  4                                [Shell, Dockerfile]  \n",
       "12                765             [TypeScript, Astro, JavaScript, Other]  \n",
       "13                220  [Python, Shell, HTML, Less, JavaScript, CSS, O...  \n",
       "14                 26                    [TypeScript, JavaScript, Other]  \n",
       "15              1,260                                 [Rust, Dockerfile]  \n",
       "16                 36  [Vim Script, C, Lua, CMake, Python, Shell, Other]  \n",
       "17                140  [Rust, HTML, JavaScript, CSS, TypeScript, Shel...  \n",
       "18                  2                                               [NA]  \n",
       "19                 22                         [Python, Jupyter Notebook]  \n",
       "20                118  [TypeScript, PowerShell, PLSQL, JavaScript, HT...  \n",
       "21                221                                    [Python, Shell]  \n",
       "22                 43  [TypeScript, JavaScript, CSS, HTML, Handlebars...  \n",
       "23                 85       [C++, C, CMake, HLSL, JavaScript, Batchfile]  \n",
       "24                  -  [JavaScript, Python, TypeScript, CSS, Shell, D...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80f6fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a96e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdeed5f0",
   "metadata": {},
   "source": [
    "### 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/  You have to find the \n",
    "following details:   \n",
    "A) Song name   \n",
    "B) Artist name   \n",
    "C) Last week rank   \n",
    "D) Peak rank   \n",
    "E) Weeks on board   \n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8432020",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79666a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd92f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on Charts Option\n",
    "charts=driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/a')\n",
    "charts.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3b27e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on hot 100 option\n",
    "hot_100=driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div[2]/div/div[1]/a/span/span')\n",
    "try:\n",
    "    hot_100.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(hot_100.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d380091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List\n",
    "Song =[]\n",
    "Artist =[]\n",
    "Last_Week_rank=[]\n",
    "Peak_rank =[]\n",
    "Weeks =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "112d4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Song Name\n",
    "try:\n",
    "    song=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/h3')\n",
    "    for i in song:\n",
    "        Song.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Song.append('NA')\n",
    "    \n",
    "# Scraping Song Artist Name\n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"][1]/ul/li[1]/span')\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append('NA')\n",
    "    \n",
    "# Scraping Song last week rank\n",
    "try:\n",
    "    last_rank=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"][1]/ul/li[7]/ul/li[3]/span')\n",
    "    for i in last_rank:\n",
    "        Last_Week_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Last_Week_rank.append('NA')\n",
    "\n",
    "# Scraping Song peak rank\n",
    "try:\n",
    "    peak=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"][1]/ul/li[7]/ul/li[4]/span')\n",
    "    for i in peak:\n",
    "        Peak_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Peak_rank.append('NA')\n",
    "\n",
    "# Scraping weeks \n",
    "try:\n",
    "    weeks=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"][1]/ul/li[7]/ul/li[5]/span')\n",
    "    for i in weeks:\n",
    "        Weeks.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Weeks.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f9a12c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Billboard=pd.DataFrame({'Song_Name':Song,\n",
    "                'Artist_Name':Artist,\n",
    "                'Last_week_rank':Last_Week_rank,\n",
    "                'Peak':Peak_rank,\n",
    "                'Weeks_on_chart':Weeks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a34eaf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Weeks_on_chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like That</td>\n",
       "      <td>Future, Metro Boomin &amp; Kendrick Lamar</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Type Shit</td>\n",
       "      <td>Future, Metro Boomin, Travis Scott &amp; Playboi C...</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beautiful Things</td>\n",
       "      <td>Benson Boone</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lose Control</td>\n",
       "      <td>Teddy Swims</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Too Sweet</td>\n",
       "      <td>Hozier</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>La Victima</td>\n",
       "      <td>Xavi</td>\n",
       "      <td>77</td>\n",
       "      <td>46</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Tucson Too Late</td>\n",
       "      <td>Jordan Davis</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Empire Now</td>\n",
       "      <td>Hozier</td>\n",
       "      <td>-</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Girl I've Always Been</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Outskirts</td>\n",
       "      <td>Sam Hunt</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Song_Name                                        Artist_Name  \\\n",
       "0               Like That              Future, Metro Boomin & Kendrick Lamar   \n",
       "1               Type Shit  Future, Metro Boomin, Travis Scott & Playboi C...   \n",
       "2        Beautiful Things                                       Benson Boone   \n",
       "3            Lose Control                                        Teddy Swims   \n",
       "4               Too Sweet                                             Hozier   \n",
       "..                    ...                                                ...   \n",
       "95             La Victima                                               Xavi   \n",
       "96        Tucson Too Late                                       Jordan Davis   \n",
       "97             Empire Now                                             Hozier   \n",
       "98  Girl I've Always Been                                     Olivia Rodrigo   \n",
       "99              Outskirts                                           Sam Hunt   \n",
       "\n",
       "   Last_week_rank Peak Weeks_on_chart  \n",
       "0               -    1              1  \n",
       "1               -    2              1  \n",
       "2               2    2             10  \n",
       "3               1    1             33  \n",
       "4               -    5              1  \n",
       "..            ...  ...            ...  \n",
       "95             77   46             15  \n",
       "96             81   81              4  \n",
       "97              -   98              1  \n",
       "98              -   99              1  \n",
       "99             92   92              3  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b027f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252f87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "688a7351",
   "metadata": {},
   "source": [
    "### 6. Scrape the details of Highest selling novels.   \n",
    "A) Book name   \n",
    "B) Author name   \n",
    "C) Volumes sold   \n",
    "D) Publisher   \n",
    "E) Genre   \n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555fb654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a1cd282",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd2a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty Lists\n",
    "Book =[]\n",
    "Author =[]\n",
    "Volumes_sold =[]\n",
    "Publisher =[]\n",
    "Genre =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b0d2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Book name\n",
    "try:\n",
    "    book=driver.find_elements(By.XPATH,'//td[@class=\"left\"][2]')\n",
    "    for i in book:\n",
    "        Book.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Book.append('NA')\n",
    "    \n",
    "# Scraping Book author's via Xpath\n",
    "try:\n",
    "    author=driver.find_elements(By.XPATH,'//td[@class=\"left\"][3]')\n",
    "    for i in author:\n",
    "        Author.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Author.append('NA')\n",
    "    \n",
    "# Scraping Volumes sold via Xpath\n",
    "try:\n",
    "    sold=driver.find_elements(By.XPATH,'//td[@class=\"left\"][4]')\n",
    "    for i in sold:\n",
    "        Volumes_sold.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Volumes_sold.append('NA')\n",
    "    \n",
    "# Scraping publisher via xPath\n",
    "try:\n",
    "    publisher=driver.find_elements(By.XPATH,'//td[@class=\"left\"][5]')\n",
    "    for i in publisher:\n",
    "        Publisher.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Publisher.append('NA')\n",
    "    \n",
    "# Scraping Genre via Xpath\n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,'//td[@class=\"last left\"]')\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2558951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "Books=pd.DataFrame({\"Book Title\":Book,\n",
    "                \"Author Name\":Author,\n",
    "                'Volumes sold':Volumes_sold,\n",
    "                'Publisher':Publisher,\n",
    "                'Genre':Genre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4163f226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Book Title       Author Name  \\\n",
      "0                                   Da Vinci Code,The        Brown, Dan   \n",
      "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
      "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
      "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
      "4                                Fifty Shades of Grey      James, E. L.   \n",
      "..                                                ...               ...   \n",
      "95                                          Ghost,The    Harris, Robert   \n",
      "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
      "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
      "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
      "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
      "\n",
      "   Volumes sold        Publisher                        Genre  \n",
      "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
      "1     4,475,152       Bloomsbury           Children's Fiction  \n",
      "2     4,200,654       Bloomsbury           Children's Fiction  \n",
      "3     4,179,479       Bloomsbury           Children's Fiction  \n",
      "4     3,758,936     Random House              Romance & Sagas  \n",
      "..          ...              ...                          ...  \n",
      "95      807,311     Random House   General & Literary Fiction  \n",
      "96      794,201          Penguin        Food & Drink: General  \n",
      "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
      "98      791,507            Orion           Biography: General  \n",
      "99      791,095          Penguin        Food & Drink: General  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cfc6911",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cade9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba7c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4369b4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9683e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3afe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c225a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef113a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
